{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "922183a9",
   "metadata": {},
   "source": [
    "# Project Description "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116ee8e",
   "metadata": {},
   "source": [
    "The goal of this project is to continue exploring convolutional neural nets, as well as transfer learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ec043c",
   "metadata": {},
   "source": [
    "# Load in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0482af4",
   "metadata": {},
   "source": [
    "I am loading in the \"Birds 525 Species - Image Classificaiton\" Dataset. I sourced this dataset from Kaggle at this url: https://www.kaggle.com/datasets/gpiosenka/100-bird-species\n",
    "\n",
    "The script Load_Image_Data.py is being used to load in these images in using keras' ImageDataGenerator, which will perform rgb intensity scaling down to [0,1] as well as specifying the batch size of 32.\n",
    "\n",
    "There are 525 unique classes to this dataset. Images are of shape (224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f8636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Load_Image_Data import Load_ImageData\n",
    "\n",
    "path = \"\\\\Bird Species Image Classification\\\\Bird Images\"\n",
    "\n",
    "train_data, test_data, val_data = Load_ImageData.Load_ImgData(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87ed22",
   "metadata": {},
   "source": [
    "Found 84635 images belonging to 525 classes.  \n",
    "Found 2625 images belonging to 525 classes.  \n",
    "Found 2625 images belonging to 525 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec65176",
   "metadata": {},
   "source": [
    "I'm going to replace the train_data I have loaded in with train data that contains data augmentation using ImageDatGenerator. Test and val data will remain the same (without any augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e592b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84635 images belonging to 525 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#respicify path to specifcily train data \n",
    "path = \"\\\\Bird Species Image Classification\\\\Bird Images\\\\train\"\n",
    "\n",
    "aug_train = ImageDataGenerator(\n",
    "    width_shift_range=0.1,      \n",
    "    height_shift_range=0.1,     \n",
    "    rotation_range=20,          \n",
    "    brightness_range=(0.5, 1.5), \n",
    "    zoom_range=0.2,             \n",
    "    horizontal_flip=True,       \n",
    "    rescale=1./255              \n",
    ")\n",
    "\n",
    "train_data = aug_train.flow_from_directory(\n",
    "    path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c18fa",
   "metadata": {},
   "source": [
    "train_data, test_data, val_data have been loaded in, now lets train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6199dd64",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd965a",
   "metadata": {},
   "source": [
    "I will start by importing the Xception pretrained model from keras for transfer learning. The Xception Architectures contains seperable convolutional layers. Traditional convoultional layers tackle spatial and rgb channel patterns in the same fell swoop, wheras seperable conv layers seperate them into different task. \n",
    "\n",
    "By loading in a pretrained model (triained on the ImageNet) training time will be reduced significantly since the trasfered model will already be able to identiy common patterns on the low level such as basic surface patterns and edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120f7083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 525)               538125    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,497,781\n",
      "Trainable params: 23,443,253\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "# Load the pre-trained Xception model without the top layers\n",
    "Xception_base = Xception(weights='imagenet', include_top=False, input_shape=[224, 224, 3])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    Xception_base, \n",
    "    \n",
    "    #output layers\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(1024, activation='relu'),\n",
    "    keras.layers.Dense(525, activation='softmax') \n",
    "    \n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c53cdf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer= \"adam\",\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94a06976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2644/2644 [==============================] - 18372s 7s/step - loss: 4.8238 - accuracy: 0.0789 - val_loss: 3.3743 - val_accuracy: 0.2491\n",
      "Epoch 2/2\n",
      "2644/2644 [==============================] - 27482s 10s/step - loss: 2.1079 - accuracy: 0.4798 - val_loss: 1.1095 - val_accuracy: 0.6872\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.samples // train_data.batch_size,\n",
    "    epochs=2,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=val_data.samples // val_data.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd3051b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('\\\\Bird Species Image Classification\\\\model_2_epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75f7fa",
   "metadata": {},
   "source": [
    "This took a very long time to train two times through the training set (almost 13 hours). I will be training the model in seperate chunks of time, saving after each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da0c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "saved_model_path = '\\\\Bird Species Image Classification\\\\model_2_epochs'\n",
    "loaded_model = tf.keras.models.load_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09deeb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625/2625 [==============================] - 196s 75ms/step - loss: 1.0076 - accuracy: 0.7234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0075669288635254, 0.7234285473823547]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d1fd9b",
   "metadata": {},
   "source": [
    "72% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99625d2b",
   "metadata": {},
   "source": [
    "Training Chunk 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04891cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2644/2644 [==============================] - 27473s 10s/step - loss: 1.1601 - accuracy: 0.7015 - val_loss: 0.6696 - val_accuracy: 0.8118\n",
      "Epoch 2/2\n",
      "2644/2644 [==============================] - 17467s 7s/step - loss: 0.8179 - accuracy: 0.7836 - val_loss: 0.5250 - val_accuracy: 0.8514\n"
     ]
    }
   ],
   "source": [
    "history = loaded_model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.samples // train_data.batch_size,\n",
    "    epochs=2,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=val_data.samples // val_data.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7490396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = '\\\\Bird Species Image Classification\\\\model_4_epochs'\n",
    "loaded_model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05a6639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625/2625 [==============================] - 224s 85ms/step - loss: 0.3783 - accuracy: 0.8914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37826618552207947, 0.8914285898208618]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4debc",
   "metadata": {},
   "source": [
    "72% -> 89% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984df342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "saved_model_path = '\\\\Bird Species Image Classification\\\\model_4_epochs'\n",
    "loaded_model = tf.keras.models.load_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759debe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625/2625 [==============================] - 287s 109ms/step - loss: 0.3783 - accuracy: 0.8914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37826618552207947, 0.8914285898208618]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de192dbe",
   "metadata": {},
   "source": [
    "Training Chunk 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf933012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2644/2644 [==============================] - 27574s 10s/step - loss: 0.6506 - accuracy: 0.8251 - val_loss: 0.5400 - val_accuracy: 0.8491\n",
      "Epoch 2/2\n",
      "2644/2644 [==============================] - 28357s 11s/step - loss: 0.5275 - accuracy: 0.8549 - val_loss: 0.4444 - val_accuracy: 0.8789\n"
     ]
    }
   ],
   "source": [
    "history = loaded_model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.samples // train_data.batch_size,\n",
    "    epochs=2,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=val_data.samples // val_data.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f1c201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625/2625 [==============================] - 342s 130ms/step - loss: 0.3362 - accuracy: 0.9021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33620306849479675, 0.9020952582359314]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7c03dc",
   "metadata": {},
   "source": [
    "Nice, 90% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5a07d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = '\\\\Bird Species Image Classification\\\\model_6_epochs'\n",
    "loaded_model.save(save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f89e37",
   "metadata": {},
   "source": [
    "Due to how computationally expensive this task is currently, I am going to retire the project at 90% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
